{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1Bm-PH3bHXZ"
   },
   "source": [
    "**登录colab读取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17118,
     "status": "ok",
     "timestamp": 1697260589451,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "ODoUtAplbQSp",
    "outputId": "cbbebcd4-60e1-410e-9e07-046c4c602909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwr6D4VebTbB"
   },
   "source": [
    "定义主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1697260592318,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "AFT40OImbazZ",
    "outputId": "18eae54e-15c0-4517-8150-0a22626f9e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14730,
     "status": "ok",
     "timestamp": 1697260608937,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "zx797TLdc0J6",
    "outputId": "2cd94f5b-12e4-4588-a131-c2ec38ece31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install omegaconf wandb hydra-core -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3LpZsVGbgN7"
   },
   "source": [
    "登录wandb获取密码和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lob7knqlRwcj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9560,
     "status": "ok",
     "timestamp": 1697260934124,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "gJA0UpBGcBRZ",
    "outputId": "5ff31525-f7f6-4a4d-a940-c33332c583ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhEOfcyqc59r"
   },
   "source": [
    "run 结合主目录地址下的文件位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA4z59ktRZNT"
   },
   "source": [
    "/content/drive/MyDrive/MDD/config/config-optuna.yaml 保存的超参数等设置\n",
    "\n",
    "/content/drive/MyDrive/MDD/src/dataset.py 更改数据集位置\n",
    "\n",
    "/content/drive/MyDrive/MDD/src/net.py 更改网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11303,
     "status": "ok",
     "timestamp": 1697260945426,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "j7QoOib0Q7YK",
    "outputId": "90bd9f47-aaab-4812-8dce-705f9011ff0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MDD/src/CNNRUN.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py\", line 119, in run\n",
      "    ret = run_job(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/content/drive/MyDrive/MDD/src/CNNRUN.py\", line 41, in main\n",
      "    setData = SetData(\n",
      "  File \"/content/drive/MyDrive/MDD/src/dataset.py\", line 31, in __init__\n",
      "    self.train_data, self.train_label, self.valid_data, self.valid_label = self.import_dataset(\n",
      "  File \"/content/drive/MyDrive/MDD/src/dataset.py\", line 50, in import_dataset\n",
      "    x = np.load(#'orientation-detection/dataset/image/over32vbpixel-gs.npy')\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 432, in load\n",
      "    return format.read_array(fid, allow_pickle=allow_pickle,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/format.py\", line 790, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python MDD/src/CNNRUN.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpuOnhHacD6T"
   },
   "source": [
    "下载必要程序（hydra加速）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15440,
     "status": "ok",
     "timestamp": 1697260629497,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "xs1T9qMpc1-K",
    "outputId": "85f26b0c-6ba0-43e9-81e2-327e34511cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hydra_optuna_sweeper\n",
      "  Downloading hydra_optuna_sweeper-1.2.0-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: hydra-core>=1.1.0.dev7 in /usr/local/lib/python3.10/dist-packages (from hydra_optuna_sweeper) (1.3.2)\n",
      "Collecting optuna<3.0.0,>=2.10.0 (from hydra_optuna_sweeper)\n",
      "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.0.dev7->hydra_optuna_sweeper) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.0.dev7->hydra_optuna_sweeper) (4.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.0.dev7->hydra_optuna_sweeper) (23.2)\n",
      "Collecting alembic (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cliff (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading cliff-4.3.0-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.8.2 (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Collecting colorlog (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (1.23.5)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.10/dist-packages (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (1.11.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (2.0.21)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (3.0.0)\n",
      "Collecting Mako (from alembic->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (3.9.0)\n",
      "Collecting autopage>=0.4.0 (from cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting cmd2>=1.0.0 (from cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.10/dist-packages (from cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (6.8.0)\n",
      "Collecting stevedore>=2.0.1 (from cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading stevedore-5.1.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.10/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (23.1.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.10/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (0.2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.4->cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (3.17.0)\n",
      "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper)\n",
      "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic->optuna<3.0.0,>=2.10.0->hydra_optuna_sweeper) (2.1.3)\n",
      "Installing collected packages: pbr, Mako, colorlog, cmd2, cmaes, autopage, stevedore, alembic, cliff, optuna, hydra_optuna_sweeper\n",
      "Successfully installed Mako-1.2.4 alembic-1.12.0 autopage-0.5.1 cliff-4.3.0 cmaes-0.10.0 cmd2-2.4.3 colorlog-6.7.0 hydra_optuna_sweeper-1.2.0 optuna-2.10.1 pbr-5.11.1 stevedore-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U hydra_optuna_sweeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOhGLGKzS2ux"
   },
   "source": [
    "**OnOff更改项：net中的frontconv中的output形状和x，perform中的L2正则化，utils中的reshape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Z7gqELLX6nm",
    "outputId": "149f8c18-42c2-48fd-ef80-a18da179bc59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Running:  90%|█████████ | 9/10 [1:07:38<07:30, 450.95s/it]\n",
      "\n",
      "Running:  20%|██        | 1/5 [06:23<25:34, 383.52s/it]\u001b[A\n",
      "Running:  40%|████      | 2/5 [12:48<19:13, 384.43s/it]\u001b[A\n",
      "Running:  60%|██████    | 3/5 [19:15<12:51, 385.67s/it]\u001b[A\n",
      "Running:  80%|████████  | 4/5 [25:45<06:27, 387.46s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_runs = 5\n",
    "\n",
    "# 创建一个tqdm进度条对象\n",
    "progress_bar = tqdm(total=num_runs, desc='Running')\n",
    "\n",
    "# 循环运行 train.py 脚本\n",
    "for _ in range(num_runs):\n",
    "    # 运行 train.py 脚本\n",
    "    subprocess.run([\"python\", \"MDD/src/CNNRUN.py\"])\n",
    "    # 更新进度条\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# 关闭进度条\n",
    "progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5759,
     "status": "ok",
     "timestamp": 1687157809446,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "KGhY7i_CdC6p",
    "outputId": "5d7dc651-6de1-4d77-e84a-cbff814d2783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: []\n",
      "Traceback (most recent call last):\n",
      "  File \"_mt19937.pyx\", line 178, in numpy.random._mt19937.MT19937._legacy_seeding\n",
      "TypeError: 'str' object cannot be interpreted as an integer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/ODGS/src/train.py\", line 61, in main\n",
      "    seed_everything(seed=cfg.seed)\n",
      "  File \"/content/drive/MyDrive/ODGS/src/train.py\", line 39, in seed_everything\n",
      "    np.random.seed(seed)\n",
      "  File \"mtrand.pyx\", line 246, in numpy.random.mtrand.RandomState.seed\n",
      "  File \"_mt19937.pyx\", line 166, in numpy.random._mt19937.MT19937._legacy_seeding\n",
      "  File \"_mt19937.pyx\", line 186, in numpy.random._mt19937.MT19937._legacy_seeding\n",
      "TypeError: Cannot cast scalar from dtype('<U22') to dtype('int64') according to the rule 'safe'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "!python MDD/src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ny7CuZWYdLW"
   },
   "source": [
    "/content/drive/MyDrive/MDD/src/CNNRUN.py \\\\\n",
    "77行修改类型 \\\\\n",
    "55行修改名字\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1358244,
     "status": "ok",
     "timestamp": 1697256461880,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "KGc-3IYhU7LE",
    "outputId": "645874cc-9c6d-4bce-e0c5-e7803aeb9b45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running:  20%|██        | 1/5 [04:43<18:52, 283.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running:  40%|████      | 2/5 [09:33<14:21, 287.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running:  60%|██████    | 3/5 [13:55<09:11, 275.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running:  80%|████████  | 4/5 [18:11<04:28, 268.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current seed: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: 100%|██████████| 5/5 [22:37<00:00, 271.58s/it]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_runs = 5\n",
    "\n",
    "# 创建一个tqdm进度条对象\n",
    "progress_bar = tqdm(total=num_runs, desc='Running')\n",
    "\n",
    "# 循环运行 train.py 脚本\n",
    "for _ in range(num_runs):\n",
    "    # 生成随机的 seed 值\n",
    "    seed = np.random.randint(0, 100)\n",
    "\n",
    "    # 读取配置文件\n",
    "    with open('ODGS/config/config-optuna.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        config['seed'] = seed\n",
    "\n",
    "    # 保存更新后的配置文件\n",
    "    with open('ODGS/config/config-optuna.yaml', 'w') as file:\n",
    "        yaml.dump(config, file)\n",
    "\n",
    "    # 打印当前使用的 seed\n",
    "    print(\"Current seed:\", seed)\n",
    "\n",
    "    # 运行 train.py 脚本\n",
    "    subprocess.run([\"python\", \"MDD/src/CNNRUN.py\"])\n",
    "\n",
    "    # 更新进度条\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# 关闭进度条\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12417,
     "status": "ok",
     "timestamp": 1697260641910,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "5BBxf4Legqnc",
    "outputId": "5fc37f5e-fafc-4c5a-a62f-33016816ab65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet-pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch) (3.27.6)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch) (17.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=0e8a73d1caf0c929123ea17e089fd5f773a837124857d61e2aead9c9e4c35c25\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 995698,
     "status": "ok",
     "timestamp": 1688000959822,
     "user": {
      "displayName": "TQ “RurIIIII” C",
      "userId": "05895762167834073294"
     },
     "user_tz": -540
    },
    "id": "mR5Yf0aQfc_J",
    "outputId": "13103e00-51e5-4fe1-d760-54c420db4ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mruriiiii\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/wandb/run-20230629_005315-nzdexs2p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-breeze-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ruriiiii/EfN-B0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ruriiiii/EfN-B0/runs/nzdexs2p\u001b[0m\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
      "100% 20.4M/20.4M [00:00<00:00, 56.2MB/s]\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "4012672\n",
      "CrossEntropy\n",
      "  0% 0/150 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "100% 150/150 [00:15<00:00,  9.45it/s]\n",
      "100% 25/25 [00:00<00:00, 59.57it/s]\n",
      "0 : train --- loss: 0.01006 acc: 0.25733, test --- loss: 0.05694 acc: 0.27400\n",
      "100% 150/150 [00:09<00:00, 16.00it/s]\n",
      "100% 25/25 [00:00<00:00, 62.43it/s]\n",
      "1 : train --- loss: 0.00954 acc: 0.27667, test --- loss: 0.06084 acc: 0.23200\n",
      "100% 150/150 [00:08<00:00, 17.73it/s]\n",
      "100% 25/25 [00:00<00:00, 43.52it/s]\n",
      "2 : train --- loss: 0.00930 acc: 0.30400, test --- loss: 0.05819 acc: 0.23400\n",
      "100% 150/150 [00:08<00:00, 17.13it/s]\n",
      "100% 25/25 [00:00<00:00, 39.25it/s]\n",
      "3 : train --- loss: 0.00883 acc: 0.36500, test --- loss: 0.05775 acc: 0.22800\n",
      "100% 150/150 [00:09<00:00, 15.65it/s]\n",
      "100% 25/25 [00:00<00:00, 54.16it/s]\n",
      "4 : train --- loss: 0.00824 acc: 0.44033, test --- loss: 0.05888 acc: 0.28200\n",
      "100% 150/150 [00:08<00:00, 17.57it/s]\n",
      "100% 25/25 [00:00<00:00, 44.17it/s]\n",
      "5 : train --- loss: 0.00753 acc: 0.52400, test --- loss: 0.05918 acc: 0.29000\n",
      "100% 150/150 [00:09<00:00, 16.65it/s]\n",
      "100% 25/25 [00:00<00:00, 57.99it/s]\n",
      "6 : train --- loss: 0.00724 acc: 0.55100, test --- loss: 0.05937 acc: 0.27800\n",
      "100% 150/150 [00:09<00:00, 16.01it/s]\n",
      "100% 25/25 [00:00<00:00, 39.71it/s]\n",
      "7 : train --- loss: 0.00719 acc: 0.55300, test --- loss: 0.06040 acc: 0.26800\n",
      "100% 150/150 [00:07<00:00, 20.07it/s]\n",
      "100% 25/25 [00:00<00:00, 61.50it/s]\n",
      "8 : train --- loss: 0.00711 acc: 0.55233, test --- loss: 0.06224 acc: 0.27000\n",
      "100% 150/150 [00:09<00:00, 15.77it/s]\n",
      "100% 25/25 [00:00<00:00, 61.15it/s]\n",
      "9 : train --- loss: 0.00723 acc: 0.53733, test --- loss: 0.06636 acc: 0.27200\n",
      "100% 150/150 [00:08<00:00, 18.21it/s]\n",
      "100% 25/25 [00:00<00:00, 42.90it/s]\n",
      "10 : train --- loss: 0.00785 acc: 0.48100, test --- loss: 0.07061 acc: 0.28000\n",
      "100% 150/150 [00:09<00:00, 16.36it/s]\n",
      "100% 25/25 [00:00<00:00, 39.92it/s]\n",
      "11 : train --- loss: 0.00814 acc: 0.47000, test --- loss: 0.06732 acc: 0.26600\n",
      "100% 150/150 [00:09<00:00, 15.25it/s]\n",
      "100% 25/25 [00:00<00:00, 55.23it/s]\n",
      "12 : train --- loss: 0.00824 acc: 0.45900, test --- loss: 0.07306 acc: 0.27200\n",
      "100% 150/150 [00:08<00:00, 17.36it/s]\n",
      "100% 25/25 [00:00<00:00, 37.66it/s]\n",
      "13 : train --- loss: 0.00779 acc: 0.50667, test --- loss: 0.10124 acc: 0.25000\n",
      "100% 150/150 [00:11<00:00, 12.90it/s]\n",
      "100% 25/25 [00:00<00:00, 54.31it/s]\n",
      "14 : train --- loss: 0.00706 acc: 0.56500, test --- loss: 0.07017 acc: 0.30400\n",
      "100% 150/150 [00:08<00:00, 17.22it/s]\n",
      "100% 25/25 [00:00<00:00, 28.23it/s]\n",
      "15 : train --- loss: 0.00603 acc: 0.63933, test --- loss: 0.06962 acc: 0.28600\n",
      "100% 150/150 [00:08<00:00, 17.66it/s]\n",
      "100% 25/25 [00:00<00:00, 58.98it/s]\n",
      "16 : train --- loss: 0.00470 acc: 0.73633, test --- loss: 0.07797 acc: 0.28400\n",
      "100% 150/150 [00:09<00:00, 15.77it/s]\n",
      "100% 25/25 [00:00<00:00, 60.06it/s]\n",
      "17 : train --- loss: 0.00332 acc: 0.82400, test --- loss: 0.07930 acc: 0.31200\n",
      "100% 150/150 [00:07<00:00, 19.30it/s]\n",
      "100% 25/25 [00:00<00:00, 58.76it/s]\n",
      "18 : train --- loss: 0.00251 acc: 0.86900, test --- loss: 0.08027 acc: 0.30200\n",
      "100% 150/150 [00:09<00:00, 15.89it/s]\n",
      "100% 25/25 [00:00<00:00, 40.30it/s]\n",
      "19 : train --- loss: 0.00210 acc: 0.89633, test --- loss: 0.08159 acc: 0.30400\n",
      "100% 150/150 [00:08<00:00, 16.72it/s]\n",
      "100% 25/25 [00:00<00:00, 36.96it/s]\n",
      "20 : train --- loss: 0.00204 acc: 0.89633, test --- loss: 0.08208 acc: 0.31600\n",
      "100% 150/150 [00:08<00:00, 17.17it/s]\n",
      "100% 25/25 [00:00<00:00, 55.01it/s]\n",
      "21 : train --- loss: 0.00197 acc: 0.91033, test --- loss: 0.08553 acc: 0.28800\n",
      "100% 150/150 [00:09<00:00, 15.32it/s]\n",
      "100% 25/25 [00:00<00:00, 58.49it/s]\n",
      "22 : train --- loss: 0.00200 acc: 0.89700, test --- loss: 0.08954 acc: 0.32000\n",
      "100% 150/150 [00:08<00:00, 16.91it/s]\n",
      "100% 25/25 [00:00<00:00, 26.85it/s]\n",
      "23 : train --- loss: 0.00291 acc: 0.84633, test --- loss: 0.09831 acc: 0.30800\n",
      "100% 150/150 [00:08<00:00, 17.16it/s]\n",
      "100% 25/25 [00:00<00:00, 62.86it/s]\n",
      "24 : train --- loss: 0.00401 acc: 0.78167, test --- loss: 0.08658 acc: 0.34400\n",
      "100% 150/150 [00:09<00:00, 15.90it/s]\n",
      "100% 25/25 [00:00<00:00, 60.93it/s]\n",
      "25 : train --- loss: 0.00434 acc: 0.75667, test --- loss: 0.09675 acc: 0.31400\n",
      "100% 150/150 [00:07<00:00, 19.49it/s]\n",
      "100% 25/25 [00:00<00:00, 60.78it/s]\n",
      "26 : train --- loss: 0.00415 acc: 0.77167, test --- loss: 0.10054 acc: 0.27600\n",
      "100% 150/150 [00:09<00:00, 16.17it/s]\n",
      "100% 25/25 [00:00<00:00, 40.94it/s]\n",
      "27 : train --- loss: 0.00393 acc: 0.78533, test --- loss: 0.09290 acc: 0.33400\n",
      "100% 150/150 [00:08<00:00, 18.10it/s]\n",
      "100% 25/25 [00:00<00:00, 40.58it/s]\n",
      "28 : train --- loss: 0.00320 acc: 0.82767, test --- loss: 0.08679 acc: 0.34200\n",
      "100% 150/150 [00:08<00:00, 16.82it/s]\n",
      "100% 25/25 [00:00<00:00, 55.01it/s]\n",
      "29 : train --- loss: 0.00215 acc: 0.88900, test --- loss: 0.08264 acc: 0.34400\n",
      "100% 150/150 [00:09<00:00, 15.32it/s]\n",
      "100% 25/25 [00:00<00:00, 54.90it/s]\n",
      "30 : train --- loss: 0.00156 acc: 0.91767, test --- loss: 0.08966 acc: 0.33800\n",
      "100% 150/150 [00:09<00:00, 15.70it/s]\n",
      "100% 25/25 [00:01<00:00, 24.52it/s]\n",
      "31 : train --- loss: 0.00118 acc: 0.93700, test --- loss: 0.08910 acc: 0.33800\n",
      "100% 150/150 [00:09<00:00, 16.64it/s]\n",
      "100% 25/25 [00:00<00:00, 60.36it/s]\n",
      "32 : train --- loss: 0.00096 acc: 0.95367, test --- loss: 0.08914 acc: 0.32400\n",
      "100% 150/150 [00:09<00:00, 15.83it/s]\n",
      "100% 25/25 [00:00<00:00, 60.00it/s]\n",
      "33 : train --- loss: 0.00086 acc: 0.96267, test --- loss: 0.08918 acc: 0.32400\n",
      "100% 150/150 [00:07<00:00, 19.13it/s]\n",
      "100% 25/25 [00:00<00:00, 55.72it/s]\n",
      "34 : train --- loss: 0.00093 acc: 0.95700, test --- loss: 0.09025 acc: 0.33400\n",
      "100% 150/150 [00:09<00:00, 15.35it/s]\n",
      "100% 25/25 [00:00<00:00, 39.50it/s]\n",
      "35 : train --- loss: 0.00084 acc: 0.96100, test --- loss: 0.09729 acc: 0.32200\n",
      "100% 150/150 [00:08<00:00, 17.23it/s]\n",
      "100% 25/25 [00:00<00:00, 42.37it/s]\n",
      "36 : train --- loss: 0.00100 acc: 0.95067, test --- loss: 0.09386 acc: 0.32200\n",
      "100% 150/150 [00:08<00:00, 16.71it/s]\n",
      "100% 25/25 [00:00<00:00, 56.47it/s]\n",
      "37 : train --- loss: 0.00167 acc: 0.91733, test --- loss: 0.10369 acc: 0.34400\n",
      "100% 150/150 [00:09<00:00, 15.24it/s]\n",
      "100% 25/25 [00:00<00:00, 58.41it/s]\n",
      "38 : train --- loss: 0.00294 acc: 0.84567, test --- loss: 0.11747 acc: 0.28600\n",
      "100% 150/150 [00:08<00:00, 18.38it/s]\n",
      "100% 25/25 [00:00<00:00, 28.76it/s]\n",
      "39 : train --- loss: 0.00394 acc: 0.79700, test --- loss: 0.09869 acc: 0.32200\n",
      "100% 150/150 [00:08<00:00, 16.90it/s]\n",
      "100% 25/25 [00:00<00:00, 58.62it/s]\n",
      "40 : train --- loss: 0.00300 acc: 0.84367, test --- loss: 0.09452 acc: 0.35800\n",
      "100% 150/150 [00:09<00:00, 15.80it/s]\n",
      "100% 25/25 [00:00<00:00, 59.89it/s]\n",
      "41 : train --- loss: 0.00232 acc: 0.88100, test --- loss: 0.08949 acc: 0.35800\n",
      "100% 150/150 [00:07<00:00, 19.37it/s]\n",
      "100% 25/25 [00:00<00:00, 56.12it/s]\n",
      "42 : train --- loss: 0.00180 acc: 0.90900, test --- loss: 0.08769 acc: 0.35200\n",
      "100% 150/150 [00:09<00:00, 15.33it/s]\n",
      "100% 25/25 [00:00<00:00, 38.16it/s]\n",
      "43 : train --- loss: 0.00136 acc: 0.93233, test --- loss: 0.08096 acc: 0.38800\n",
      "100% 150/150 [00:08<00:00, 16.83it/s]\n",
      "100% 25/25 [00:00<00:00, 37.12it/s]\n",
      "44 : train --- loss: 0.00078 acc: 0.96500, test --- loss: 0.08562 acc: 0.35000\n",
      "100% 150/150 [00:08<00:00, 16.98it/s]\n",
      "100% 25/25 [00:00<00:00, 58.12it/s]\n",
      "45 : train --- loss: 0.00060 acc: 0.97133, test --- loss: 0.08751 acc: 0.36600\n",
      "100% 150/150 [00:09<00:00, 15.31it/s]\n",
      "100% 25/25 [00:00<00:00, 59.34it/s]\n",
      "46 : train --- loss: 0.00058 acc: 0.97233, test --- loss: 0.08850 acc: 0.36200\n",
      "100% 150/150 [00:08<00:00, 17.83it/s]\n",
      "100% 25/25 [00:00<00:00, 30.25it/s]\n",
      "47 : train --- loss: 0.00064 acc: 0.97200, test --- loss: 0.08860 acc: 0.36800\n",
      "100% 150/150 [00:08<00:00, 17.35it/s]\n",
      "100% 25/25 [00:00<00:00, 59.99it/s]\n",
      "48 : train --- loss: 0.00070 acc: 0.96233, test --- loss: 0.08954 acc: 0.37200\n",
      "100% 150/150 [00:11<00:00, 13.06it/s]\n",
      "100% 25/25 [00:00<00:00, 61.27it/s]\n",
      "49 : train --- loss: 0.00056 acc: 0.97933, test --- loss: 0.09690 acc: 0.34800\n",
      "100% 150/150 [00:07<00:00, 20.09it/s]\n",
      "100% 25/25 [00:00<00:00, 62.95it/s]\n",
      "50 : train --- loss: 0.00085 acc: 0.95900, test --- loss: 0.10607 acc: 0.35400\n",
      "100% 150/150 [00:09<00:00, 16.35it/s]\n",
      "100% 25/25 [00:00<00:00, 41.07it/s]\n",
      "51 : train --- loss: 0.00185 acc: 0.90633, test --- loss: 0.09974 acc: 0.35800\n",
      "100% 150/150 [00:07<00:00, 19.29it/s]\n",
      "100% 25/25 [00:00<00:00, 44.72it/s]\n",
      "52 : train --- loss: 0.00241 acc: 0.87700, test --- loss: 0.09285 acc: 0.34800\n",
      "100% 150/150 [00:08<00:00, 16.96it/s]\n",
      "100% 25/25 [00:00<00:00, 58.07it/s]\n",
      "53 : train --- loss: 0.00246 acc: 0.87900, test --- loss: 0.08775 acc: 0.38200\n",
      "100% 150/150 [00:09<00:00, 15.88it/s]\n",
      "100% 25/25 [00:00<00:00, 58.15it/s]\n",
      "54 : train --- loss: 0.00254 acc: 0.86700, test --- loss: 0.08871 acc: 0.37800\n",
      "100% 150/150 [00:08<00:00, 18.74it/s]\n",
      "100% 25/25 [00:00<00:00, 39.11it/s]\n",
      "55 : train --- loss: 0.00171 acc: 0.91600, test --- loss: 0.08112 acc: 0.35800\n",
      "100% 150/150 [00:09<00:00, 16.48it/s]\n",
      "100% 25/25 [00:00<00:00, 62.52it/s]\n",
      "56 : train --- loss: 0.00089 acc: 0.95500, test --- loss: 0.08590 acc: 0.37200\n",
      "100% 150/150 [00:08<00:00, 17.81it/s]\n",
      "100% 25/25 [00:00<00:00, 44.64it/s]\n",
      "57 : train --- loss: 0.00059 acc: 0.97367, test --- loss: 0.08933 acc: 0.39000\n",
      "100% 150/150 [00:08<00:00, 17.54it/s]\n",
      "100% 25/25 [00:00<00:00, 60.02it/s]\n",
      "58 : train --- loss: 0.00047 acc: 0.97900, test --- loss: 0.09193 acc: 0.39400\n",
      "100% 150/150 [00:09<00:00, 16.56it/s]\n",
      "100% 25/25 [00:00<00:00, 40.33it/s]\n",
      "59 : train --- loss: 0.00045 acc: 0.98033, test --- loss: 0.09192 acc: 0.39000\n",
      "100% 150/150 [00:07<00:00, 19.32it/s]\n",
      "100% 25/25 [00:00<00:00, 58.37it/s]\n",
      "60 : train --- loss: 0.00046 acc: 0.97867, test --- loss: 0.09201 acc: 0.39000\n",
      "100% 150/150 [00:09<00:00, 15.35it/s]\n",
      "100% 25/25 [00:00<00:00, 58.13it/s]\n",
      "61 : train --- loss: 0.00043 acc: 0.97867, test --- loss: 0.09273 acc: 0.40200\n",
      "100% 150/150 [00:08<00:00, 17.13it/s]\n",
      "100% 25/25 [00:00<00:00, 37.78it/s]\n",
      "62 : train --- loss: 0.00043 acc: 0.97900, test --- loss: 0.09025 acc: 0.38000\n",
      "100% 150/150 [00:08<00:00, 17.65it/s]\n",
      "100% 25/25 [00:00<00:00, 40.03it/s]\n",
      "63 : train --- loss: 0.00037 acc: 0.98333, test --- loss: 0.10149 acc: 0.38800\n",
      "100% 150/150 [00:09<00:00, 15.94it/s]\n",
      "100% 25/25 [00:00<00:00, 60.12it/s]\n",
      "64 : train --- loss: 0.00112 acc: 0.95400, test --- loss: 0.10697 acc: 0.38800\n",
      "100% 150/150 [00:07<00:00, 19.37it/s]\n",
      "100% 25/25 [00:00<00:00, 46.27it/s]\n",
      "65 : train --- loss: 0.00229 acc: 0.87933, test --- loss: 0.09661 acc: 0.36400\n",
      "100% 150/150 [00:08<00:00, 16.72it/s]\n",
      "100% 25/25 [00:00<00:00, 59.39it/s]\n",
      "66 : train --- loss: 0.00223 acc: 0.88767, test --- loss: 0.08918 acc: 0.39600\n",
      "100% 150/150 [00:09<00:00, 15.54it/s]\n",
      "100% 25/25 [00:00<00:00, 26.77it/s]\n",
      "67 : train --- loss: 0.00179 acc: 0.91067, test --- loss: 0.09653 acc: 0.36400\n",
      "100% 150/150 [00:08<00:00, 17.34it/s]\n",
      "100% 25/25 [00:00<00:00, 56.05it/s]\n",
      "68 : train --- loss: 0.00162 acc: 0.92533, test --- loss: 0.08954 acc: 0.37000\n",
      "100% 150/150 [00:09<00:00, 15.46it/s]\n",
      "100% 25/25 [00:00<00:00, 58.22it/s]\n",
      "69 : train --- loss: 0.00099 acc: 0.95000, test --- loss: 0.09014 acc: 0.39000\n",
      "100% 150/150 [00:08<00:00, 18.74it/s]\n",
      "100% 25/25 [00:00<00:00, 57.16it/s]\n",
      "70 : train --- loss: 0.00044 acc: 0.98100, test --- loss: 0.09400 acc: 0.42800\n",
      "100% 150/150 [00:09<00:00, 15.82it/s]\n",
      "100% 25/25 [00:00<00:00, 41.17it/s]\n",
      "71 : train --- loss: 0.00043 acc: 0.97933, test --- loss: 0.09480 acc: 0.40000\n",
      "100% 150/150 [00:08<00:00, 17.25it/s]\n",
      "100% 25/25 [00:00<00:00, 38.34it/s]\n",
      "72 : train --- loss: 0.00042 acc: 0.98100, test --- loss: 0.09540 acc: 0.41000\n",
      "100% 150/150 [00:08<00:00, 17.30it/s]\n",
      "100% 25/25 [00:00<00:00, 60.35it/s]\n",
      "73 : train --- loss: 0.00028 acc: 0.98867, test --- loss: 0.09568 acc: 0.41000\n",
      "100% 150/150 [00:09<00:00, 16.47it/s]\n",
      "100% 25/25 [00:00<00:00, 60.51it/s]\n",
      "74 : train --- loss: 0.00022 acc: 0.99100, test --- loss: 0.09689 acc: 0.40400\n",
      "100% 150/150 [00:07<00:00, 19.78it/s]\n",
      "100% 25/25 [00:00<00:00, 31.42it/s]\n",
      "75 : train --- loss: 0.00024 acc: 0.98867, test --- loss: 0.10038 acc: 0.39000\n",
      "100% 150/150 [00:08<00:00, 17.00it/s]\n",
      "100% 25/25 [00:00<00:00, 63.26it/s]\n",
      "76 : train --- loss: 0.00026 acc: 0.98667, test --- loss: 0.10558 acc: 0.38200\n",
      "100% 150/150 [00:09<00:00, 16.33it/s]\n",
      "100% 25/25 [00:00<00:00, 36.85it/s]\n",
      "77 : train --- loss: 0.00055 acc: 0.97900, test --- loss: 0.10131 acc: 0.39800\n",
      "100% 150/150 [00:07<00:00, 18.98it/s]\n",
      "100% 25/25 [00:00<00:00, 61.07it/s]\n",
      "78 : train --- loss: 0.00192 acc: 0.90667, test --- loss: 0.20012 acc: 0.31800\n",
      "100% 150/150 [00:09<00:00, 16.46it/s]\n",
      "100% 25/25 [00:00<00:00, 41.91it/s]\n",
      "79 : train --- loss: 0.00476 acc: 0.75833, test --- loss: 0.12021 acc: 0.34200\n",
      "100% 150/150 [00:07<00:00, 20.47it/s]\n",
      "100% 25/25 [00:00<00:00, 47.69it/s]\n",
      "80 : train --- loss: 0.00310 acc: 0.84400, test --- loss: 0.09058 acc: 0.37600\n",
      "100% 150/150 [00:09<00:00, 16.07it/s]\n",
      "100% 25/25 [00:00<00:00, 62.80it/s]\n",
      "81 : train --- loss: 0.00151 acc: 0.92300, test --- loss: 0.08319 acc: 0.38600\n",
      "100% 150/150 [00:08<00:00, 17.63it/s]\n",
      "100% 25/25 [00:00<00:00, 39.67it/s]\n",
      "82 : train --- loss: 0.00084 acc: 0.96533, test --- loss: 0.08671 acc: 0.38400\n",
      "100% 150/150 [00:07<00:00, 18.91it/s]\n",
      "100% 25/25 [00:00<00:00, 40.56it/s]\n",
      "83 : train --- loss: 0.00063 acc: 0.97100, test --- loss: 0.08962 acc: 0.40400\n",
      "100% 150/150 [00:09<00:00, 16.54it/s]\n",
      "100% 25/25 [00:00<00:00, 59.37it/s]\n",
      "84 : train --- loss: 0.00046 acc: 0.97700, test --- loss: 0.09182 acc: 0.39400\n",
      "100% 150/150 [00:07<00:00, 19.66it/s]\n",
      "100% 25/25 [00:00<00:00, 61.17it/s]\n",
      "85 : train --- loss: 0.00030 acc: 0.98800, test --- loss: 0.09297 acc: 0.39000\n",
      "100% 150/150 [00:11<00:00, 13.13it/s]\n",
      "100% 25/25 [00:00<00:00, 59.71it/s]\n",
      "86 : train --- loss: 0.00035 acc: 0.98633, test --- loss: 0.09341 acc: 0.39400\n",
      "100% 150/150 [00:08<00:00, 18.55it/s]\n",
      "100% 25/25 [00:00<00:00, 26.98it/s]\n",
      "87 : train --- loss: 0.00021 acc: 0.99133, test --- loss: 0.09405 acc: 0.39200\n",
      "100% 150/150 [00:08<00:00, 16.85it/s]\n",
      "100% 25/25 [00:00<00:00, 58.36it/s]\n",
      "88 : train --- loss: 0.00029 acc: 0.99133, test --- loss: 0.09653 acc: 0.40000\n",
      "100% 150/150 [00:09<00:00, 15.88it/s]\n",
      "100% 25/25 [00:00<00:00, 61.40it/s]\n",
      "89 : train --- loss: 0.00038 acc: 0.98167, test --- loss: 0.09706 acc: 0.41200\n",
      "100% 150/150 [00:07<00:00, 20.15it/s]\n",
      "100% 25/25 [00:00<00:00, 59.30it/s]\n",
      "90 : train --- loss: 0.00044 acc: 0.97700, test --- loss: 0.10531 acc: 0.38800\n",
      "100% 150/150 [00:09<00:00, 16.66it/s]\n",
      "100% 25/25 [00:00<00:00, 41.71it/s]\n",
      "91 : train --- loss: 0.00069 acc: 0.96533, test --- loss: 0.10066 acc: 0.39400\n",
      "100% 150/150 [00:07<00:00, 19.91it/s]\n",
      "100% 25/25 [00:00<00:00, 44.96it/s]\n",
      "92 : train --- loss: 0.00202 acc: 0.91033, test --- loss: 0.10235 acc: 0.38400\n",
      "100% 150/150 [00:09<00:00, 16.29it/s]\n",
      "100% 25/25 [00:00<00:00, 59.37it/s]\n",
      "93 : train --- loss: 0.00152 acc: 0.92700, test --- loss: 0.10203 acc: 0.39800\n",
      "100% 150/150 [00:09<00:00, 16.59it/s]\n",
      "100% 25/25 [00:00<00:00, 52.59it/s]\n",
      "94 : train --- loss: 0.00094 acc: 0.95800, test --- loss: 0.10231 acc: 0.37800\n",
      "100% 150/150 [00:07<00:00, 20.08it/s]\n",
      "100% 25/25 [00:00<00:00, 40.80it/s]\n",
      "95 : train --- loss: 0.00092 acc: 0.95733, test --- loss: 0.10903 acc: 0.37200\n",
      "100% 150/150 [00:08<00:00, 16.94it/s]\n",
      "100% 25/25 [00:00<00:00, 60.34it/s]\n",
      "96 : train --- loss: 0.00058 acc: 0.97367, test --- loss: 0.09128 acc: 0.41600\n",
      "100% 150/150 [00:07<00:00, 19.21it/s]\n",
      "100% 25/25 [00:00<00:00, 44.49it/s]\n",
      "97 : train --- loss: 0.00037 acc: 0.98533, test --- loss: 0.09379 acc: 0.39000\n",
      "100% 150/150 [00:08<00:00, 16.69it/s]\n",
      "100% 25/25 [00:00<00:00, 59.18it/s]\n",
      "98 : train --- loss: 0.00026 acc: 0.98800, test --- loss: 0.09452 acc: 0.39200\n",
      "100% 150/150 [00:08<00:00, 17.33it/s]\n",
      "100% 25/25 [00:00<00:00, 25.47it/s]\n",
      "99 : train --- loss: 0.00022 acc: 0.98933, test --- loss: 0.09590 acc: 0.38200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▃▁▃▂▃▂▃▄▄▄▄▅▅▄▄▃▆▇▆▆▆▇▆▇▇▇▇▆▇█▇▄▇█▇▇▇▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▃▂▂▃▃▃▂▃▃▃▃▃▃▃▃█▂▃▃▃▃▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▁▄▄▃▃▅▆▇▇▆▆▇██▇▇▇███▇▇███▇▇███▇▇████▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▆▆▇▅▃▂▂▄▄▂▁▁▃▃▂▁▁▁▃▂▁▁▁▂▂▁▁▁▂▂▁▁▁▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.0959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.98933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.00022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlively-breeze-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ruriiiii/EfN-B0/runs/nzdexs2p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230629_005315-nzdexs2p/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ODGS/src/EfNB0torch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据形状： (60000, 28, 28)\n",
      "填充后数据形状： (60000, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你有一个 (60000, 28, 28) 的数据集\n",
    "data = np.load(r'B:\\dataset\\Orientation_GS_dataset_unit8\\rotated_MNIST\\rotated_MNIST.npy')  # 示例数据\n",
    "\n",
    "# 使用 np.pad 在每个图像周围添加 2 像素的 0 填充\n",
    "padded_data = np.pad(data, ((0, 0), (2, 2), (2, 2)), mode='constant', constant_values=0)\n",
    "\n",
    "print(\"原始数据形状：\", data.shape)\n",
    "print(\"填充后数据形状：\", padded_data.shape)\n",
    "\n",
    "np.save(r'B:\\dataset\\Orientation_GS_dataset_unit8\\rotated_MNIST\\rotated_MNIST_padded.npy', padded_data)\n",
    "plt.imshow(padded_data[1551])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.13-py3-none-any.whl (171 kB)\n",
      "     ---------------------------------------- 0.0/171.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 171.7/171.7 kB 10.8 MB/s eta 0:00:00\n",
      "Collecting scikit-image>=0.21.0\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.6/12.9 MB 13.3 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 1.5/12.9 MB 15.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.1/12.9 MB 21.6 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.1/12.9 MB 32.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.5/12.9 MB 38.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.9 MB 72.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 59.5 MB/s eta 0:00:00\n",
      "Collecting albucore>=0.0.13\n",
      "  Downloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
      "Collecting pydantic>=2.7.0\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "     ---------------------------------------- 0.0/423.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 423.9/423.9 kB 27.6 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.24.4\n",
      "  Downloading numpy-2.0.1-cp39-cp39-win_amd64.whl (16.6 MB)\n",
      "     ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "     ----------- --------------------------- 4.9/16.6 MB 156.6 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 11.0/16.6 MB 131.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 15.2/16.6 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.6/16.6 MB 108.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 16.6/16.6 MB 81.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\nougata_share_pc_2\\anaconda3\\envs\\c-backup\\lib\\site-packages (from albumentations) (6.0)\n",
      "Collecting opencv-python-headless>=4.9.0.80\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "     ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "     ----- --------------------------------- 5.3/38.8 MB 112.6 MB/s eta 0:00:01\n",
      "     ---------- --------------------------- 11.1/38.8 MB 108.8 MB/s eta 0:00:01\n",
      "     ------------- ------------------------ 14.1/38.8 MB 110.0 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 17.5/38.8 MB 93.9 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 23.3/38.8 MB 93.9 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 29.1/38.8 MB 131.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 34.9/38.8 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  38.7/38.8 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  38.7/38.8 MB 108.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 38.8/38.8 MB 65.5 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.9.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\nougata_share_pc_2\\anaconda3\\envs\\c-backup\\lib\\site-packages (from albumentations) (1.10.1)\n",
      "Collecting eval-type-backport\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: tomli>=2.0.1 in c:\\users\\nougata_share_pc_2\\anaconda3\\envs\\c-backup\\lib\\site-packages (from albucore>=0.0.13->albumentations) (2.0.1)\n",
      "Collecting numpy>=1.24.4\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting pydantic-core==2.20.1\n",
      "  Downloading pydantic_core-2.20.1-cp39-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.9/1.9 MB 126.4 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\nougata_share_pc_2\\anaconda3\\envs\\c-backup\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (9.4.0)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.7.24-py3-none-any.whl (226 kB)\n",
      "     ---------------------------------------- 0.0/226.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 226.2/226.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\nougata_share_pc_2\\anaconda3\\envs\\c-backup\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (23.0)\n",
      "Collecting imageio>=2.33\n",
      "  Downloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
      "     ---------------------------------------- 0.0/313.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 313.5/313.5 kB ? eta 0:00:00\n",
      "Collecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\nougata_share_pc_2\\anaconda3\\envs\\c-backup\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2.8.4)\n",
      "Installing collected packages: typing-extensions, numpy, lazy-loader, eval-type-backport, annotated-types, tifffile, pydantic-core, opencv-python-headless, imageio, scikit-image, pydantic, albucore, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] アクセスが拒否されました。: 'C:\\\\Users\\\\nougata_share_pc_2\\\\anaconda3\\\\envs\\\\C-backup\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPZ6IueVxTL9CYGaMcoLmDK",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
